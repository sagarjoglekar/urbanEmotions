\section{Introduction}

Deep neural nets are progressing at an amazing pace over the past decade. The community and the technology has been breaking grounds across the fields. 
When it comes to classification and inference for specific tasks like object detection, scene detection, language modelling etc, Deep learning has been at the fore front. 
But the  reasons behind a particular decision taken by a deep model, more or less still remains a mystery. This gap is by some accounts call the explainability gap, or the black box problem of Neural nets. 
Explain-ability and understanding the deep reasoning behind decisions is one of the most researched problems in the machine learning community.
\par
The problem of explain-ability becomes even more abstract and obscured, when we are dealing with tasks that handle meta, and abstract quantities like sentiment, affects and aesthetics. Despite the black box like nature, deep neural networks have done remarkable strides in understanding creativity \cite{redi20146}, memorability \cite{Isola2011} or beauty \cite{schifanella2015image} at a meta level, and works great in providing inferences. 
These works explore perceptual qualities of media objects using deep learning, and treat the explainability of the models using round about methods like perturbation 
of input and understanding correlation of several governing variables with decisions of the network etc. 
These methods are perfectly valid and do give some interesting insights into the decision influencing factors for the models, however still fail to explain the knowledge that the network has learn't and which it uses to drive the decisions that it takes. 
\par 
Despite these issues, computational aesthetics have reaped a lot of benefits from the advances in Deep neural networks. Works like \cite{khosla2014makes} \cite{quercia2014aesthetic} \cite{naik2014streetscore} \cite{parislooklikeparis}, underscore the utility of machine learning in computational aesthetics in urban settings.   In this paper we propose a generalizable pipeline for analysing geo-referenced images (FaceLift) for affective and/or aesthetic metrics. For the purpose of specificity, we conduct all our studies on the dimension of beauty in urban images. The pipeline learns the concept urban affect and then for a given street-view image finds an approximate transformation so as to maximize or minimize the presence of said affect. The is done by generating synthetic images to maximize the affect and then finding a best match to the synthetic images from the street-view database under some compositional constraints. We show that the humans overwhelmingly agree with the pipeline's transformations using a crowd sourcing experiment and then show that the transformations of the pipeline can be explained using well known urban design metrics.