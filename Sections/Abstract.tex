\begin{abstract}
Interpretable and explainable insights from deep-learning models is still a working problem. This problem is also apparent in the cross-disciplinary work which uses deep-learning to quantify urban environments. In this paper we propose a Deep Learning driven pipeline which works on streetview images, called \textsl{FaceLift}. The pipeline allows us to learn, transform and explain, intangible concepts in urban settings like beauty, safety etc. For the sake of this paper we work with the dimension of beauty in urban scenes. We do so with the help of generative models, that generates approximate transformations of streetview images to maximize or minimize beauty. We further develop literature driven urban design metrics to explain the properties in a scene that makes it beautiful. We implement these metrics using computer vision driven algorithms. We validate our pipeline's transformational capabilities using crowd sourced experiments. We conclude by summarizing actual expert views about the use of such a pipeline and metrics, and discuss the broader implications. 
\end{abstract}