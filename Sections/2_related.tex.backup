\section{Related Work}
\label{sec:related}
%\ns{This needs more work.}
Previous work has focused on collecting ground truth data about how people perceive urban spaces, on predicting urban qualities from visual data, and on generating synthetic images that enhance a given quality (e.g., beauty). 

\mbox{}\\
\noindent
\sj
{\textbf{Perception of physical spaces.}
The%re has been a lot of work done in 
literature in the area of quantifying %how we as humans 
people perceive urban environments is pretty rich. From the seminal work about urban vitality by Jane Jacobs\cite{jacobs1961death} to imagining urban design though patterns\cite{alexander1977pattern}, there has been a %constant
continuous effort to understand and intervene to make our cities more livable and enjoyable. A lot of work was done in the field of human behaviour analysis, e.g.
%like
Roger Ulrich's work to understand affective responses to urban environments\cite{ulrich1983aesthetic}. Some studies looked into self rated perception of urban aesthetics against well known metrics like complexity\cite{kaplan1972rated} or perception of nature\cite{kaplan1989experience}. There was empirical work done using trained survey takers, to understand how people perceive scenic beauty\cite{real2000classification}. All this work in the fields of psychology, environmental design and behavioural sciences showed that humans are quite predictive when it comes to how they perceive physical spaces}
\mbox{}\\

\mbox{}\\
\noindent
\textbf{Ground truth of urban perceptions.} So far the most detailed studies of perceptions of urban environments and their visual appearance have relied on personal interviews and observation of city streets: for example, some researchers relied on annotations of video recordings by experts~\cite{sampson04seeing}, while others have used participant ratings of simulated (rather than existing) street scenes~\cite{lindal2012}. The web has recently been used to survey a large number of individuals. Place Pulse is a website that asks a series of binary perception questions (such as `Which place looks safer [between the two]?') across a large number of geo-tagged images~\cite{salesses2013collaborative}. In a similar way, Quercia \emph{et al.} collected pairwise judgments about the extent to which urban scenes are considered quiet, beautiful and happy~\cite{quercia2014aesthetic}. They were then able to analyze the scenes together with their ratings using image-processing tools, and found that the amount of greenery in any given scene was associated with all three attributes and that cars and fortress-like buildings were associated with sadness. Taken all together, their results pointed in the same direction: urban elements that hinder social interactions were undesirable, while elements that increase interactions were the ones that should be integrated by urban planners to retrofit cities for greater happiness.
\sj{Some studies also linked aesthetics of physical spaces to physical activity, like the study by Ball et.al \cite{ball2001perceived}, where through 3.3k self reported surveys, they show that urban aesthetics have a positive effect on the urge of walking. Another work \cite{giles2005increasing} showed through interviews of 1.8k participants that attractiveness of public open spaces impact positively on increased walking. Finally, a large scale study using a crowd sourced interface\footnote{\url{http://scenic.mysociety.org/)}} looked at relationship between `scenic-ness' of a place with land cover and geography. }
\mbox{}\\

\mbox{}\\
\noindent
\textbf{Deep learning and the city.} Computer vision techniques have increasingly become more sophisticated. Deep learning techniques, in particular, have been recently used to accurately predict urban beauty~\cite{dubey2016deep,seresinhe2017using}, urban change~\cite{naik2017computer}, and even crime~\cite{DeNadai16,arietta2014city}. These works also did some interesting analysis of the data to understand how safety, depression, beauty and other such dimensions are perceived across urban spaces.  \cite{dubey2016deep} also utilized deep learning methods to train models capable of comparing two urban images for their perception values in terms of beauty et.al. \sj{Recent work has also explored utility of deep learning techniques in understanding relationship between urban frontage and housing prices\cite{frontage}. Another work looked at predicting house prices using deeplearning on satellite as well as street view images\cite{law2018take}.} However even these works did not dive into the reasoning aspect of these models.
\mbox{}\\

\mbox{}\\
\noindent
\textbf{Generative models.} \sj{Since the introduction of Generative adversarial Networks\cite{goodfellow2014generative}}, deep learning has recently been used not only to analyse existing images but also to generate new ones.\sj{These family of deep networks have evolved into various forms, from super resolution image generators\cite{ledig2017photo}, to networks that could in-paint from context\cite{pathak2016context}}. In the past couple of years, there have been papers which exploit generative version of neural nets to delve into the aspects of explain-ability.\sj{Recently GANs were used to do semantic segmentation of images\cite{luc2016semantic}. This approach paves a way for using latent knowledge learned by the classifiers to explain away semantics in the image.}Nguyen \emph{et al.}~\cite{nguyen2016synthesizing} used generative networks to create a natural-looking image that maximizes a specific neuron. In theory, the resulting image is the one that ``best activates'' the neuron under consideration (e.g., that associated with urban beauty). In practice, it is still a synthetic template that needs further processing to look realistic. 
\mbox{}\\

\mbox{}
To sum up, a lot of work has gone into collecting ground truth data about how people tend to perceive urban spaces, and into building accurate predictions models of urban qualities. However,  little work has gone into models that generate realistic urban scenes and that offer human-interpretable explanations of what they generate. 


