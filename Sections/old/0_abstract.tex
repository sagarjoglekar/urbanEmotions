\begin{abstract}
\ns{Have a go at reformulating slightly to fit the TOMM call better}
In computer vision, deep learning techniques have recently been used to predict whether urban scenes are likely to be considered beautiful, and it turns out that these techniques do so quite accurately. To support urban interventions, however, one needs to go beyond \emph{predicting} beauty and tackle the challenge of \emph{recreating} beauty.  Unfortunately, deep learning techniques have not been designed with that challenge in mind. Given their ``black-box nature'', they cannot even explain why a scene has been predicted to be beautiful. To partly fix that, we propose a deep learning framework (which we name  FaceLift) that is able to both \emph{beautify} existing Google Street views and \emph{explain} which urban elements make those transformed scenes beautiful. To quantitatively evaluate our framework, we cannot resort to any existing metric (as the research problem at hand has never been faced before) and need to  formulate new ones. These new metrics should ideally capture the presence (or absence) of elements that make urban spaces great. Upon a review of the urban planning literature, we identify four main metrics: walkability, green, openness, and visual complexity.  For all the four metrics, the beautified scenes meet the expectations set by the literature on what great spaces tend to be made of. These results suggest that, in the future, as our framework's components are further researched and become better and more sophisticated, it is not hard to imagine technologies that will be able to accurately and efficiently support architects and planners in the design of the spaces we intuitively love. 


%Interpretable and explainable insights from deep-learning models is still a working problem. This problem is also apparent in the cross-disciplinary work which uses deep-learning to quantify urban environments. In this paper we propose a Deep Learning driven pipeline which works on streetview images, called \textsl{FaceLift}. The pipeline allows us to learn, transform and explain, intangible concepts in urban settings like beauty, safety etc. For the sake of this paper we work with the dimension of beauty in urban scenes. We do so with the help of generative models, that generates approximate transformations of streetview images to maximize or minimize beauty. We further develop literature driven urban design metrics to explain the properties in a scene that makes it beautiful. We implement these metrics using computer vision driven algorithms. We validate our pipeline's transformational capabilities using crowd sourced experiments. We conclude by summarizing actual expert views about the use of such a pipeline and metrics, and discuss the broader implications. 
\end{abstract}