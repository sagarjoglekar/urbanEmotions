\section{Related Work}
We explore related work in the fields of computational aesthetics and in the area of data driven inferences in urban environments. 
Early work in the field of computational aesthetics done by Datta \cite{datta2008algorithmic} looked at the beauty aspect of images using hand-crafted visual features and datasets collected from photo-contest websites. It showed that subjective properties like beauty can be estimated using computer vision techniques, provided we have good data.  The introduction of deep-learning in this field boosted the activity. Post deep-learning works \cite{khosla2014makes,Wang:2015:USA:2832415.2832579,schifanella2015image} explored the dimensions of beauty, aesthetics and their linkages to popularity and engagement over the web. Despite being very subjective dimensions, these works showed impressive performance in quantifying them. 
%But all of them have a gap in explaining why their models have a good performance and what features have the classifiers learnt to look for. These questions boil down to the concept of explainability of machine learning models. 
%In the past few years, there has been some progress made in the field of computational aesthetics. The work done by Datta \cite{datta2008algorithmic} looked at the beauty aspect of images by using crowd sourced annotation and then building classifiers on top. The introduction of deep-learning to this field boosted the activity. Works such as \cite{Isola2011} used it to understand memorability. Some other works like \cite{khosla2014makes} \cite{Wang:2015:USA:2832415.2832579} \cite{schifanella2015image} , explored the dimensions of beauty, aesthetics and their linkages to popularity and engagement over the web. The work by Redi \cite{redi20146} looked at quantification of the notion of creativity in the short microvideos. These works look at properties which are abstract and very subjective. But still they all claim impressive performances in these aspects. But all of them have a gap in explaining why their models have a good performance and what features have the classifiers learnt to look for. These questions boil down to the concept of explainability of machine learning models. 
\par
Extending quantification of subjective information to the realm of maps was explored by works such as \cite{quercia2014shortest,quercia2015chatty,quercia2015smelly,aiello2016chatty}. These works took the subjective dimensions such as beauty, loudness, and smelly-ness and augment this information onto real world maps to present a new dimension in which one can explore their world.
Works like \cite{naik2014streetscore,salesses2013collaborative}, collected and analyzed responses to images of urbanscapes across different subjective dimensions including safety, depression, beauty and built deep-learning models on their data. An extension of this work  \cite{dubey2016deep} used deep learning  to train models capable to rank urban images according to these subjective dimensions. Other works used deep-learning \cite{,seresinhe2017using,Law:2017:ACN:3149808.3149810,seresinhe2015quantifying,naik2017computer} to not just quantify urban environments, but to draw inferences and insights regarding outcome variables like poverty, mental health etc.  The limitation of these works is that the models developed for urban perception are not interpretable, i.e., they provide predictions regarding subjective qualities of urban images, without explaining the reasoning behind the predicted score. This motivates our work as we aim at making these inferences interpretable to most agents who are learned in the science of urban design.

%The questions pertaining to what the network learns semantically have been explored for popular use cases \cite{mao2014explain,karpathy2015deep}  but still remain largely unexplored for intangible classes representing concepts like beauty, sentiment etc.  In this paper, we apply this general scheme to the specific problem of predicting beauty and explaining the changes that influence the beautification process. 

%In the past couple of years, there have been papers which exploit generative version of neural nets to delve into the aspects of explainability.
%The design of GAN inherently encodes the knowledge learned by a neural network from the distribution of training data into a form of code based generator \cite{goodfellow2014generative}. To build on to of the generative models, the paper by Ngyuen et.al \cite{nguyen2016synthesizing} looks at using generative networks to create the best Natural-like image that maximizes a particular neuron in the network. The resulting image can be imagined as the image of the cumulative knowledge learned by the network that activates the neuron under consideration. If this neuron is the output label neuron, the resulting images summarize the knowledge of the network that describes a particular label.

%In the area of urban perception and urban affects, some recent works have shown some progress. Works like Street score \cite{naik2014streetscore} and  \cite{salesses2013collaborative}, have demonstrated innovative techniques of collecting urban perception data. They also did some interesting analysis of the data to understand how safety, depression, beauty and other such dimensions are perceived across urban spaces. An extension work  \cite{dubey2016deep} also utilized deep learning methods to train models capable of comparing two urban images for their perception values in terms of beauty et.al. However even these works did not dive into the reasoning aspect of these models.
%In the past couple of years, there have been papers which exploit generative version of neural nets to delve into the aspects of explainability.
%The design of GAN inherently encodes the knowledge learned by a neural network from the distribution of training data into a form of code based generator \cite{goodfellow2014generative}. To build on to of the generative models, the paper by Ngyuen et.al \cite{nguyen2016synthesizing} looks at using generative networks to create the best Natural-like image that maximizes a particular neuron in the network. The resulting image can be imagined as the image of the cumulative knowledge learned by the network that activates the neuron under consideration. If this neuron is the output label neuron, the resulting images summarize the knowledge of the network that describes a particular label.

\par
%The literature discussed here shows that there are gaps in understanding of the models that do very well when it comes to perceptual properties. On the other hand, we also see that there has been some progress in visualizing and understanding the internal reasoning of neural networks \textbf{[REF]}. We exploit recent developments in this field to \textbf{[...]} 
%This motivates our work, which proposes a series of steps comprising a pipeline, which can streamline the task of explaining computational aesthetics models. A more specific use case of this is understanding urban properties.