\section{Related Work}

\textbf{[@Sagar please add more on urban computing e.g. happy Maps]}


\textbf{[@Sagar please add real deep learning papers below, otherwise the last sentence of this paragraph doesn't hold]}

This paper follows up on previous research in the field of computational aesthetics, namely that branch of computer vision dedicated to the analysis of visual quality and appeal, and, more in general, of subjective properties of visual data.
Early work in the field done by Datta \cite{datta2008algorithmic} looked at the beauty aspect of images using hand-crafted visual features and datasets collected from photo-contest websites. The introduction of deep-learning in this field boosted the activity. Works such as \cite{Isola2011} used it to understand memorability. Some other works like \cite{khosla2014makes} \cite{Wang:2015:USA:2832415.2832579} \cite{schifanella2015image} , explored the dimensions of beauty, aesthetics and their linkages to popularity and engagement over the web. The work by Redi \cite{redi20146} looked at quantification of the notion of creativity in the short microvideos. These works look at properties which are abstract and very subjective. But still they all claim impressive performances in these aspects. But all of them have a gap in explaining why their models have a good performance and what features have the classifiers learnt to look for. These questions boil down to the concept of explainability of machine learning models. 
%In the past few years, there has been some progress made in the field of computational aesthetics. The work done by Datta \cite{datta2008algorithmic} looked at the beauty aspect of images by using crowd sourced annotation and then building classifiers on top. The introduction of deep-learning to this field boosted the activity. Works such as \cite{Isola2011} used it to understand memorability. Some other works like \cite{khosla2014makes} \cite{Wang:2015:USA:2832415.2832579} \cite{schifanella2015image} , explored the dimensions of beauty, aesthetics and their linkages to popularity and engagement over the web. The work by Redi \cite{redi20146} looked at quantification of the notion of creativity in the short microvideos. These works look at properties which are abstract and very subjective. But still they all claim impressive performances in these aspects. But all of them have a gap in explaining why their models have a good performance and what features have the classifiers learnt to look for. These questions boil down to the concept of explainability of machine learning models. 

\par
Similar to this paper, few works have focused on developing comptational aesthetics tools and datasets specific to urban perception. Works like StreetScore \cite{naik2014streetscore} and  \cite{salesses2013collaborative}, collected and analyzed responses to  images of urbanscapes across different subjective dimensions including safety, depression, beauty. An extension of this work  \cite{dubey2016deep} used deep learning  to train models capable to rank urban images according to these subjective dimensions. The limitation of most of these works is that the models developed for urban perception are not interpretable, i.e., they provide predictions regarding subjective qualities of urban images, without explaining the reasoning behind the predicted score. Although very accurate, these models might not be useful in context of urban planning, since ... \textbf{[@Daniele: help?]}

\textbf{[@Sagar the work from ATI is missing? Please add it and check differences.]}


%In the past couple of years, there have been papers which exploit generative version of neural nets to delve into the aspects of explainability.
%The design of GAN inherently encodes the knowledge learned by a neural network from the distribution of training data into a form of code based generator \cite{goodfellow2014generative}. To build on to of the generative models, the paper by Ngyuen et.al \cite{nguyen2016synthesizing} looks at using generative networks to create the best Natural-like image that maximizes a particular neuron in the network. The resulting image can be imagined as the image of the cumulative knowledge learned by the network that activates the neuron under consideration. If this neuron is the output label neuron, the resulting images summarize the knowledge of the network that describes a particular label.

%In the area of urban perception and urban affects, some recent works have shown some progress. Works like Street score \cite{naik2014streetscore} and  \cite{salesses2013collaborative}, have demonstrated innovative techniques of collecting urban perception data. They also did some interesting analysis of the data to understand how safety, depression, beauty and other such dimensions are perceived across urban spaces. An extension work  \cite{dubey2016deep} also utilized deep learning methods to train models capable of comparing two urban images for their perception values in terms of beauty et.al. However even these works did not dive into the reasoning aspect of these models.
%In the past couple of years, there have been papers which exploit generative version of neural nets to delve into the aspects of explainability.
%The design of GAN inherently encodes the knowledge learned by a neural network from the distribution of training data into a form of code based generator \cite{goodfellow2014generative}. To build on to of the generative models, the paper by Ngyuen et.al \cite{nguyen2016synthesizing} looks at using generative networks to create the best Natural-like image that maximizes a particular neuron in the network. The resulting image can be imagined as the image of the cumulative knowledge learned by the network that activates the neuron under consideration. If this neuron is the output label neuron, the resulting images summarize the knowledge of the network that describes a particular label.

\par
The literature discussed here shows that there are gaps in understanding of the models that do very well when it comes to perceptual properties. On the other hand, we also see that there has been some progress in visualizing and understanding the internal reasoning of neural networks \textbf{[REF]}. We exploit recent developments in this field to \textbf{[...]} 
%This motivates our work, which proposes a series of steps comprising a pipeline, which can streamline the task of explaining computational aesthetics models. A more specific use case of this is understanding urban properties.